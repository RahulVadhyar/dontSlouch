{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1td6hkAVIiEgmC1ufG8QmqIsHe29_1ggC","authorship_tag":"ABX9TyNErMezRdtWqyk4krKrrIio"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install tensorflow\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kMW2LL3hvoeS","executionInfo":{"status":"ok","timestamp":1714376024328,"user_tz":-330,"elapsed":7227,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"9d7815a0-45f0-4e6e-98f6-14d5fc23a653"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.2)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from google.colab import drive\n"],"metadata":{"id":"D4npxzmKxqMv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZAmdf7SxwaZ","executionInfo":{"status":"ok","timestamp":1714377982841,"user_tz":-330,"elapsed":4128,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"5d3c2e64-a80b-490c-d6dc-35b378c7659e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["folder_path = '/content/drive/My Drive/data'\n","import os\n","contents = os.listdir(folder_path)\n","print(contents)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sraYrQG5CMP","executionInfo":{"status":"ok","timestamp":1714378053824,"user_tz":-330,"elapsed":513,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"ae0b4c28-fa0f-45d9-cee7-220a381a7cfd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['validation', 'training']\n"]}]},{"cell_type":"code","source":["pip install numpy opencv-python\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xXN9l4T-4gEP","executionInfo":{"status":"ok","timestamp":1714378440604,"user_tz":-330,"elapsed":8750,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"43139782-81ce-4684-fde1-b22ea10928c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","def load_and_preprocess_image(path, size=(224, 224)):\n","    image = cv2.imread(path, cv2.IMREAD_COLOR)\n","    image = cv2.resize(image, size, interpolation=cv2.INTER_AREA)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image = image / 255.0\n","    return image\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","def create_augmented_data_generator():\n","    # Initialize the ImageDataGenerator with augmentation parameters\n","    train_datagen = ImageDataGenerator(\n","        rescale=1./255,   # Normalize images\n","        rotation_range=40,  # Random rotations between 0-40 degrees\n","        width_shift_range=0.2,  # Random horizontal shifts\n","        height_shift_range=0.2,  # Random vertical shifts\n","        shear_range=0.2,  # Shearing\n","        zoom_range=0.2,  # Zooming\n","        horizontal_flip=True,  # Horizontal flipping\n","        fill_mode='nearest'  # Strategy to fill newly created pixels\n","    )\n","    return train_datagen\n","\n","\n","train_datagen = create_augmented_data_generator()\n","train_generator = train_datagen.flow_from_directory(\n","    directory='/content/drive/My Drive/data/training',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","\n"],"metadata":{"id":"xKvX1c4P8Gr_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714382567757,"user_tz":-330,"elapsed":916,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"00470e42-be00-4383-cff3-9e00b03401cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 79 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","def create_model(input_shape):\n","    model = Sequential([\n","        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n","        MaxPooling2D(2, 2),\n","        Conv2D(64, (3, 3), activation='relu'),\n","        MaxPooling2D(2, 2),\n","        Conv2D(128, (3, 3), activation='relu'),\n","        MaxPooling2D(2, 2),\n","        Flatten(),\n","        Dense(512, activation='relu'),\n","        Dropout(0.5),\n","        Dense(1, activation='sigmoid')\n","    ])\n","\n","\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","model = create_model((224, 224, 3))\n"],"metadata":{"id":"XZLDs_RnKzsq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","\n","train_generator = train_datagen.flow_from_directory(\n","    '/content/drive/My Drive/data/training',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    '/content/drive/My Drive/data/validation',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g5AS0pwyLJvf","executionInfo":{"status":"ok","timestamp":1714382795049,"user_tz":-330,"elapsed":605,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"6fdd8308-58c4-4b14-bcef-3725fad1ba36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 79 images belonging to 2 classes.\n","Found 10 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["history = model.fit(\n","    train_generator,\n","    steps_per_epoch=3,  # Since you have 79 training images and a batch size of 32, set steps_per_epoch to (total_images / batch_size)\n","    epochs=10,\n","    validation_data=validation_generator,\n","    validation_steps=1\n",")\n","model.save('/content/drive/My Drive/model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dWKvHBGoLYcT","executionInfo":{"status":"ok","timestamp":1714383904778,"user_tz":-330,"elapsed":179737,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"18509308-bd25-4a76-c564-241702f8c829"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","3/3 [==============================] - 13s 3s/step - loss: 0.6547 - accuracy: 0.6329 - val_loss: 0.7560 - val_accuracy: 0.5000\n","Epoch 2/10\n","3/3 [==============================] - 13s 3s/step - loss: 0.6784 - accuracy: 0.6329 - val_loss: 0.7425 - val_accuracy: 0.5000\n","Epoch 3/10\n","3/3 [==============================] - 13s 5s/step - loss: 0.6540 - accuracy: 0.6329 - val_loss: 0.7346 - val_accuracy: 0.5000\n","Epoch 4/10\n","3/3 [==============================] - 14s 3s/step - loss: 0.6526 - accuracy: 0.6329 - val_loss: 0.7276 - val_accuracy: 0.5000\n","Epoch 5/10\n","3/3 [==============================] - 13s 4s/step - loss: 0.6640 - accuracy: 0.6329 - val_loss: 0.7062 - val_accuracy: 0.5000\n","Epoch 6/10\n","3/3 [==============================] - 12s 3s/step - loss: 0.6718 - accuracy: 0.6329 - val_loss: 0.7176 - val_accuracy: 0.5000\n","Epoch 7/10\n","3/3 [==============================] - 13s 5s/step - loss: 0.6683 - accuracy: 0.6329 - val_loss: 0.7113 - val_accuracy: 0.5000\n","Epoch 8/10\n","3/3 [==============================] - 13s 5s/step - loss: 0.6716 - accuracy: 0.6329 - val_loss: 0.7078 - val_accuracy: 0.5000\n","Epoch 9/10\n","3/3 [==============================] - 13s 4s/step - loss: 0.6641 - accuracy: 0.6329 - val_loss: 0.7046 - val_accuracy: 0.5000\n","Epoch 10/10\n","3/3 [==============================] - 13s 5s/step - loss: 0.6544 - accuracy: 0.6329 - val_loss: 0.7277 - val_accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"code","source":["train_loss, train_accuracy = model.evaluate(train_generator)\n","print(f\"Training Accuracy: {train_accuracy}\")\n","val_loss, val_accuracy = model.evaluate(validation_generator)\n","print(f\"Validation Accuracy: {val_accuracy}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-0Mnrj_Mm5h","executionInfo":{"status":"ok","timestamp":1714383921481,"user_tz":-330,"elapsed":7199,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"215d43e3-6465-46c7-c81d-633c486b81b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3/3 [==============================] - 5s 951ms/step - loss: 0.6573 - accuracy: 0.6329\n","Training Accuracy: 0.6329113841056824\n","1/1 [==============================] - 0s 463ms/step - loss: 0.7277 - accuracy: 0.5000\n","Validation Accuracy: 0.5\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","import cv2\n","\n","def load_and_prepare_image(img_path, target_size=(224, 224)):\n","    img = image.load_img(img_path, target_size=target_size)\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    img_array /= 255.0\n","    return img_array\n","\n","model = tf.keras.models.load_model('/content/drive/My Drive/model.h5')\n","\n","new_image_path = '/content/WIN_20240429_15_05_56_Pro.jpg'\n","new_image = load_and_prepare_image(new_image_path)\n","\n","predictions = model.predict(new_image)\n","predicted_class = 'Good Posture' if predictions[0] > 0.5 else 'Bad Posture'\n","\n","print(f\"The image was classified as: {predicted_class}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dzExT-IKNRMN","executionInfo":{"status":"ok","timestamp":1714383945215,"user_tz":-330,"elapsed":5396,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"3f3b7650-4264-41a5-e63d-5cecbd6ad431"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 164ms/step\n","The image was classified as: Bad Posture\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"5H-OGLMkRjDs"}},{"cell_type":"markdown","source":["# TRIAL\n","\n","```\n","# This is formatted as code\n","```\n","\n"],"metadata":{"id":"V4WDfkLJRi3v"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Step 1: Define the CNN model\n","def create_model(input_shape):\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n","        tf.keras.layers.MaxPooling2D(2, 2),\n","        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","        tf.keras.layers.MaxPooling2D(2, 2),\n","        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n","        tf.keras.layers.MaxPooling2D(2, 2),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(512, activation='relu'),\n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n","    ])\n","    return model\n","\n","# Step 2: Load and preprocess the data\n","train_datagen = ImageDataGenerator(\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    '/content/drive/My Drive/data/training',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    '/content/drive/My Drive/data/validation',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","# Step 3: Create and compile the model\n","model = create_model((224, 224, 3))\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Step 4: Train the model\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=3,\n","    epochs=20,  # Increase epochs to 20\n","    validation_data=validation_generator,\n","    validation_steps=1\n",")\n","\n","# Step 5: Save the model\n","model.save('/content/drive/My Drive/model_try1.h5')\n","\n","# Step 6: Evaluate the model\n","train_loss, train_accuracy = model.evaluate(train_generator)\n","print(f\"Training Accuracy: {train_accuracy}\")\n","\n","val_loss, val_accuracy = model.evaluate(validation_generator)\n","print(f\"Validation Accuracy: {val_accuracy}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GFtMx2DvSuET","executionInfo":{"status":"ok","timestamp":1714385692616,"user_tz":-330,"elapsed":361477,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"1e7fcd09-106e-47ab-bb41-c9401ba95b72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 79 images belonging to 2 classes.\n","Found 10 images belonging to 2 classes.\n","Epoch 1/20\n","3/3 [==============================] - 15s 4s/step - loss: 681.4786 - accuracy: 0.5570 - val_loss: 1.8041 - val_accuracy: 0.5000\n","Epoch 2/20\n","3/3 [==============================] - 12s 3s/step - loss: 179.7945 - accuracy: 0.6203 - val_loss: 0.7281 - val_accuracy: 0.5000\n","Epoch 3/20\n","3/3 [==============================] - 13s 3s/step - loss: 50.4149 - accuracy: 0.3924 - val_loss: 0.7047 - val_accuracy: 0.5000\n","Epoch 4/20\n","3/3 [==============================] - 12s 3s/step - loss: 19.2310 - accuracy: 0.5316 - val_loss: 0.6915 - val_accuracy: 0.5000\n","Epoch 5/20\n","3/3 [==============================] - 12s 3s/step - loss: 6.1660 - accuracy: 0.4430 - val_loss: 0.6929 - val_accuracy: 0.5000\n","Epoch 6/20\n","3/3 [==============================] - 13s 3s/step - loss: 0.6902 - accuracy: 0.5443 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 7/20\n","3/3 [==============================] - 24s 7s/step - loss: 0.6620 - accuracy: 0.6203 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 8/20\n","3/3 [==============================] - 13s 5s/step - loss: 0.6483 - accuracy: 0.6329 - val_loss: 0.6930 - val_accuracy: 0.5000\n","Epoch 9/20\n","3/3 [==============================] - 13s 5s/step - loss: 0.6717 - accuracy: 0.5823 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 10/20\n","3/3 [==============================] - 13s 4s/step - loss: 0.6816 - accuracy: 0.6329 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 11/20\n","3/3 [==============================] - 13s 4s/step - loss: 0.6760 - accuracy: 0.6582 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 12/20\n","3/3 [==============================] - 13s 4s/step - loss: 0.6545 - accuracy: 0.6329 - val_loss: 0.6930 - val_accuracy: 0.5000\n","Epoch 13/20\n","3/3 [==============================] - 12s 4s/step - loss: 0.7004 - accuracy: 0.6329 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 14/20\n","3/3 [==============================] - 13s 3s/step - loss: 0.6653 - accuracy: 0.5570 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 15/20\n","3/3 [==============================] - 13s 4s/step - loss: 0.6743 - accuracy: 0.6329 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 16/20\n","3/3 [==============================] - 13s 4s/step - loss: 0.6593 - accuracy: 0.6076 - val_loss: 0.6930 - val_accuracy: 0.5000\n","Epoch 17/20\n","3/3 [==============================] - 13s 3s/step - loss: 0.6450 - accuracy: 0.6203 - val_loss: 0.6928 - val_accuracy: 0.5000\n","Epoch 18/20\n","3/3 [==============================] - 13s 4s/step - loss: 0.6573 - accuracy: 0.5949 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 19/20\n","3/3 [==============================] - 14s 3s/step - loss: 0.6511 - accuracy: 0.6076 - val_loss: 0.6935 - val_accuracy: 0.5000\n","Epoch 20/20\n","3/3 [==============================] - 13s 4s/step - loss: 0.6854 - accuracy: 0.6456 - val_loss: 0.6937 - val_accuracy: 0.5000\n","3/3 [==============================] - 4s 898ms/step - loss: 0.6853 - accuracy: 0.6329\n","Training Accuracy: 0.6329113841056824\n","1/1 [==============================] - 0s 439ms/step - loss: 0.6937 - accuracy: 0.5000\n","Validation Accuracy: 0.5\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Define data paths and augmentations\n","train_data_dir = '/content/drive/My Drive/data/training'\n","validation_data_dir = '/content/drive/My Drive/data/validation'\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","# Create and compile the model\n","def create_model(input_shape):\n","    model = Sequential([\n","        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n","        MaxPooling2D(2, 2),\n","        Conv2D(64, (3, 3), activation='relu'),\n","        MaxPooling2D(2, 2),\n","        Conv2D(128, (3, 3), activation='relu'),\n","        MaxPooling2D(2, 2),\n","        Flatten(),\n","        Dense(512, activation='relu'),\n","        Dropout(0.25),  # Add dropout regularization\n","        Dense(1, activation='sigmoid')\n","    ])\n","\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","                  loss='binary_crossentropy',\n","                  metrics=['accuracy'])\n","    return model\n","\n","model = create_model((224, 224, 3))\n","\n","# Implement early stopping based on validation loss\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","# Train the model with early stopping\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=len(train_generator),\n","    epochs=20,  # Increase epochs for more training iterations\n","    validation_data=validation_generator,\n","    validation_steps=len(validation_generator),\n","    callbacks=[early_stopping]\n",")\n","\n","# Save the model\n","model.save('/content/drive/My Drive/model_optimized.h5')\n","\n","# Evaluate the model\n","train_loss, train_accuracy = model.evaluate(train_generator)\n","print(f\"Training Accuracy: {train_accuracy}\")\n","val_loss, val_accuracy = model.evaluate(validation_generator)\n","print(f\"Validation Accuracy: {val_accuracy}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qY0zaxveRmyE","executionInfo":{"status":"ok","timestamp":1714384552161,"user_tz":-330,"elapsed":99427,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"72f1df31-b27c-4d34-d1af-43268f2a7b57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 79 images belonging to 2 classes.\n","Found 10 images belonging to 2 classes.\n","Epoch 1/20\n","3/3 [==============================] - 17s 4s/step - loss: 3.7319 - accuracy: 0.6203 - val_loss: 2.6365 - val_accuracy: 0.5000\n","Epoch 2/20\n","3/3 [==============================] - 13s 5s/step - loss: 1.5520 - accuracy: 0.3671 - val_loss: 0.6933 - val_accuracy: 0.5000\n","Epoch 3/20\n","3/3 [==============================] - 13s 5s/step - loss: 0.6666 - accuracy: 0.6203 - val_loss: 0.7936 - val_accuracy: 0.5000\n","Epoch 4/20\n","3/3 [==============================] - 13s 3s/step - loss: 0.7054 - accuracy: 0.6329 - val_loss: 0.8065 - val_accuracy: 0.5000\n","Epoch 5/20\n","3/3 [==============================] - 13s 3s/step - loss: 0.6989 - accuracy: 0.6329 - val_loss: 0.7081 - val_accuracy: 0.5000\n","3/3 [==============================] - 6s 1s/step - loss: 0.6882 - accuracy: 0.6329\n","Training Accuracy: 0.6329113841056824\n","1/1 [==============================] - 1s 535ms/step - loss: 0.6933 - accuracy: 0.5000\n","Validation Accuracy: 0.5\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wACD6pFHYOZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, concatenate\n","\n","# Define a function to create the model with additional inputs for distance and angle\n","def create_model_with_features(input_shape, num_distances, num_angles):\n","    # Image input\n","    image_input = Input(shape=input_shape, name='image_input')\n","    x = Conv2D(32, (3, 3), activation='relu')(image_input)\n","    x = MaxPooling2D(2, 2)(x)\n","    x = Conv2D(64, (3, 3), activation='relu')(x)\n","    x = MaxPooling2D(2, 2)(x)\n","    x = Conv2D(128, (3, 3), activation='relu')(x)\n","    x = MaxPooling2D(2, 2)(x)\n","    x = Flatten()(x)\n","    x = Dense(512, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","\n","    # Distance and angle inputs\n","    distance_input = Input(shape=(num_distances,), name='distance_input')\n","    angle_input = Input(shape=(num_angles,), name='angle_input')\n","\n","    # Concatenate image features with distance and angle features\n","    combined = concatenate([x, distance_input, angle_input])\n","\n","    # Dense layers for classification\n","    x = Dense(256, activation='relu')(combined)\n","    x = Dropout(0.5)(x)\n","    output = Dense(1, activation='sigmoid')(x)\n","\n","    # Create model\n","    model = Model(inputs=[image_input, distance_input, angle_input], outputs=output)\n","\n","    # Compile the model\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","# Example usage:\n","# Assuming you have extracted features (distances and angles) from your posture data\n","# and loaded your image data as X_images and Y_labels\n","X_images =\n","Y_labels =\n","X_distances =\n","X_angles =\n","\n","# Define input shapes\n","image_input_shape = (224, 224, 3)  # Assuming image size is 224x224 and 3 channels (RGB)\n","num_distances = X_distances.shape[1]  # Number of distance features\n","num_angles = X_angles.shape[1]  # Number of angle features\n","\n","# Create the model\n","model = create_model_with_features(image_input_shape, num_distances, num_angles)\n","\n","# Train the model\n","history = model.fit(\n","    {'image_input': X_images, 'distance_input': X_distances, 'angle_input': X_angles},\n","    Y_labels,\n","    epochs=10,\n","    validation_split=0.2\n",")\n"],"metadata":{"id":"D7tCC8oCYODd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"sr6149Q7acpN"}},{"cell_type":"markdown","source":[],"metadata":{"id":"fK7zFs43acbO"}},{"cell_type":"code","source":["pip install mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRKkXXOZacJT","executionInfo":{"status":"ok","timestamp":1714387437543,"user_tz":-330,"elapsed":106935,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"126bde7a-ad20-4843-cd62-9a5da4ef3616"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mediapipe\n","  Downloading mediapipe-0.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n","Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mediapipe) (2.2.1+cu121)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->mediapipe)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->mediapipe)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->mediapipe)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->mediapipe)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->mediapipe)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->mediapipe)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->mediapipe)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->mediapipe)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->mediapipe)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->mediapipe)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->mediapipe)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->mediapipe)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mediapipe) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mediapipe) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, sounddevice, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mediapipe\n","Successfully installed mediapipe-0.10.11 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sounddevice-0.4.6\n"]}]},{"cell_type":"code","source":["import mediapipe as mp\n","import cv2\n","import numpy as np\n","import math\n","\n","mp_pose = mp.solutions.pose\n","pose = mp_pose.Pose()\n","\n","def calculate_features(image):\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    results = pose.process(image_rgb)\n","    landmarks = results.pose_landmarks.landmark\n","\n","    if not results.pose_landmarks:\n","        return None  # No keypoints detected\n","\n","    # Define the required keypoints for feature calculation\n","    def get_xy(idx):\n","        return landmarks[idx].x, landmarks[idx].y\n","\n","    l_shoulder = get_xy(mp_pose.PoseLandmark.LEFT_SHOULDER.value)\n","    r_shoulder = get_xy(mp_pose.PoseLandmark.RIGHT_SHOULDER.value)\n","    l_ear = get_xy(mp_pose.PoseLandmark.LEFT_EAR.value)\n","    l_hip = get_xy(mp_pose.PoseLandmark.LEFT_HIP.value)\n","\n","    # Calculate distances and angles\n","    def find_distance(p1, p2):\n","        return math.sqrt((p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2)\n","\n","    def find_angle(p1, p2):\n","        theta = math.acos((p2[1] - p1[1]) * (-p1[1]) / (math.sqrt((p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2) * p1[1]))\n","        degree = int(180 / math.pi) * theta\n","        return degree\n","\n","    features = [\n","        find_distance(l_shoulder, r_shoulder),\n","        find_angle(l_shoulder, l_ear),\n","        find_angle(l_hip, l_shoulder)\n","    ]\n","\n","    return features\n","def preprocess_dataset(image_paths):\n","    data = []\n","    labels = []  # Assume labels are given with paths\n","\n","    for path, label in image_paths:\n","        image = cv2.imread(path)\n","        image = cv2.resize(image, (224, 224))\n","        features = calculate_features(image)\n","        if features:\n","            data.append(features)\n","            labels.append(label)\n","\n","    return np.array(data), np.array(labels)\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","def create_feature_model():\n","    model = Sequential([\n","        Dense(32, activation='relu', input_shape=(3,)),  # Input layer adjusted for 3 features\n","        Dropout(0.2),\n","        Dense(64, activation='relu'),\n","        Dense(1, activation='sigmoid')\n","    ])\n","\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","model = create_feature_model()\n","image_paths = [('/content/WIN_20240429_15_16_10_Pro.jpg', 0), ('/content/WIN_20240429_15_05_56_Pro.jpg', 1)]  # Example paths and labels\n","X, y = preprocess_dataset(image_paths)\n","model.fit(X, y, epochs=10, validation_split=0.2)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hp-zLCp_abtA","executionInfo":{"status":"ok","timestamp":1714387451623,"user_tz":-330,"elapsed":6036,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"ec822d35-0063-4126-da72-2c3b2c0e46bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1/1 [==============================] - 4s 4s/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 4.3875 - val_accuracy: 0.0000e+00\n","Epoch 2/10\n","1/1 [==============================] - 0s 87ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 4.6498 - val_accuracy: 0.0000e+00\n","Epoch 3/10\n","1/1 [==============================] - 0s 118ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 4.9315 - val_accuracy: 0.0000e+00\n","Epoch 4/10\n","1/1 [==============================] - 0s 126ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 5.2103 - val_accuracy: 0.0000e+00\n","Epoch 5/10\n","1/1 [==============================] - 0s 142ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 5.4876 - val_accuracy: 0.0000e+00\n","Epoch 6/10\n","1/1 [==============================] - 0s 118ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 5.7706 - val_accuracy: 0.0000e+00\n","Epoch 7/10\n","1/1 [==============================] - 0s 173ms/step - loss: 0.1067 - accuracy: 1.0000 - val_loss: 6.0403 - val_accuracy: 0.0000e+00\n","Epoch 8/10\n","1/1 [==============================] - 0s 169ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 6.3071 - val_accuracy: 0.0000e+00\n","Epoch 9/10\n","1/1 [==============================] - 0s 113ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 6.5565 - val_accuracy: 0.0000e+00\n","Epoch 10/10\n","1/1 [==============================] - 0s 144ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 6.7942 - val_accuracy: 0.0000e+00\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7825fc8cb010>"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["validation_data = [('/content/WIN_20240429_15_16_07_Pro.jpg', 0), ('/content/WIN_20240429_15_05_56_Pro.jpg', 1)]\n","X_val, y_val = preprocess_dataset(validation_data)\n","accuracy = model.evaluate(X_val, y_val)\n","print(\"Validation Accuracy:\", accuracy)\n","model.save('posture_model.h5')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUDl3yzqdbyT","executionInfo":{"status":"ok","timestamp":1714387779505,"user_tz":-330,"elapsed":7,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"bb9f1221-1ce1-4456-bed0-eaee69660b46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step - loss: 3.1181 - accuracy: 0.5000\n","Validation Accuracy: [3.118060827255249, 0.5]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"code","source":["saved_model = tf.keras.models.load_model('posture_model.h5')\n","new_image_path = '/content/good_posture_032.jpg'\n","new_image = cv2.imread(new_image_path)\n","new_image_features = calculate_features(new_image)\n","if new_image_features:\n","    new_image_features = np.array([new_image_features])\n","    prediction = saved_model.predict(new_image_features)\n","    predicted_class = 'good' if prediction[0] > 0.5 else 'bad'\n","    print(\"Predicted Class:\", predicted_class)\n","else:\n","    print(\"Could not detect keypoints in the image.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySI80hhdeYwy","executionInfo":{"status":"ok","timestamp":1714387994059,"user_tz":-330,"elapsed":1280,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"c8af7c43-f53e-44f8-ff40-fabbde119faa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 64ms/step\n","Predicted Class: bad\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"75JyEXkYgPSy"}},{"cell_type":"markdown","source":[],"metadata":{"id":"kgaRrfkVgPED"}},{"cell_type":"markdown","source":["TRYINGG"],"metadata":{"id":"hSf2KhaygPA4"}},{"cell_type":"markdown","source":[],"metadata":{"id":"rTYSG4vBkbTN"}},{"cell_type":"code","source":["import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","good_frames = 0\n","bad_frames = 0\n","\n","mp_pose = mp.solutions.pose\n","pose = mp_pose.Pose()\n","\n","file_name = 'input.mp4'\n","cap = cv2.VideoCapture(file_name)\n","\n","# Open CSV file for writing\n","with open('posture_data.csv', mode='w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerow(['Left Shoulder X', 'Left Shoulder Y', 'Right Shoulder X', 'Right Shoulder Y',\n","                     'Left Ear X', 'Left Ear Y', 'Left Hip X', 'Left Hip Y', 'Neck Inclination', 'Torso Inclination', 'Label'])\n","\n","    print('Processing..')\n","    while cap.isOpened():\n","        success, image = cap.read()\n","        if not success:\n","            print(\"Null.Frames\")\n","            break\n","\n","        h, w = image.shape[:2]\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        keypoints = pose.process(image)\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        lm = keypoints.pose_landmarks\n","        lmPose = mp_pose.PoseLandmark\n","\n","        if lm is not None:\n","            l_shldr_x = int(lm.landmark[lmPose.LEFT_SHOULDER].x * w)\n","            l_shldr_y = int(lm.landmark[lmPose.LEFT_SHOULDER].y * h)\n","            r_shldr_x = int(lm.landmark[lmPose.RIGHT_SHOULDER].x * w)\n","            r_shldr_y = int(lm.landmark[lmPose.RIGHT_SHOULDER].y * h)\n","            l_ear_x = int(lm.landmark[lmPose.LEFT_EAR].x * w)\n","            l_ear_y = int(lm.landmark[lmPose.LEFT_EAR].y * h)\n","            l_hip_x = int(lm.landmark[lmPose.LEFT_HIP].x * w)\n","            l_hip_y = int(lm.landmark[lmPose.LEFT_HIP].y * h)\n","            offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","            neck_inclination = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n","            torso_inclination = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n","\n","            # Determine label based on posture\n","            label = 'good' if offset < 100 and neck_inclination < 40 and torso_inclination < 10 else 'bad'\n","\n","            # Write posture data to CSV file\n","            writer.writerow([l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y,\n","                             l_ear_x, l_ear_y, l_hip_x, l_hip_y,\n","                             neck_inclination, torso_inclination, label])\n","\n","print('Finished.')\n","cap.release()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4141wljtEtc","executionInfo":{"status":"ok","timestamp":1714391639896,"user_tz":-330,"elapsed":424,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"1a4ad993-d96c-46a8-8119-f5aa8ba39514"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing..\n","Finished.\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"DjgzQjmpkbQA"}},{"cell_type":"code","source":["\n","folder_path = '/content/drive/MyDrive/data'  # Adjust the path to where your images are stored within Google Drive\n","csv_file_path = '/content/drive/My Drive/posture_data1.csv'  # Adjust the path where you want to save the CSV\n"],"metadata":{"id":"o47MqCV9wR2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:  # Avoid division by zero\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        l_ear_x = lm.landmark[mp_pose.PoseLandmark.LEFT_EAR].x * w\n","        l_ear_y = lm.landmark[mp_pose.PoseLandmark.LEFT_EAR].y * h\n","        l_hip_x = lm.landmark[mp_pose.PoseLandmark.LEFT_HIP].x * w\n","        l_hip_y = lm.landmark[mp_pose.PoseLandmark.LEFT_HIP].y * h\n","        offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        neck_inclination = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n","        torso_inclination = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n","\n","        # Determine label based on posture\n","        label = 'good' if offset < 100 and neck_inclination < 40 and torso_inclination < 10 else 'bad'\n","\n","        # Write posture data to CSV file\n","        writer.writerow([l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y,\n","                         l_ear_x, l_ear_y, l_hip_x, l_hip_y,\n","                         neck_inclination, torso_inclination, label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_in_folder(folder_path, csv_file_path):\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Left Shoulder X', 'Left Shoulder Y', 'Right Shoulder X', 'Right Shoulder Y',\n","                         'Left Ear X', 'Left Ear Y', 'Left Hip X', 'Left Hip Y', 'Neck Inclination',\n","                         'Torso Inclination', 'Label'])\n","\n","        pose = mp_pose.Pose()\n","        for filename in os.listdir(folder_path):\n","            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n","                image_path = os.path.join(folder_path, filename)\n","                print(\"Processing:\", image_path)  # Add this line for debugging\n","                process_image(image_path, writer, pose)\n","            else:\n","                print(\"Skipping file:\", filename)  # Add this line for debugging\n","        pose.close()\n","\n","if __name__ == \"__main__\":\n","    folder_path = '/content/drive/MyDrive/data'  # Adjust the path to where your images are stored within Google Drive\n","    csv_file_path = '/content/posture_data3.csv'\n","    process_images_in_folder(folder_path, csv_file_path)\n","    print('Finished processing images and saving data to CSV.')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4CQy3MZpovh","executionInfo":{"status":"ok","timestamp":1714392766531,"user_tz":-330,"elapsed":376,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"b2e28899-8b24-4963-d79b-52f651d36ee3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Skipping file: validation\n","Skipping file: training\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        l_ear_x = lm.landmark[mp_pose.PoseLandmark.LEFT_EAR].x * w\n","        l_ear_y = lm.landmark[mp_pose.PoseLandmark.LEFT_EAR].y * h\n","        l_hip_x = lm.landmark[mp_pose.PoseLandmark.LEFT_HIP].x * w\n","        l_hip_y = lm.landmark[mp_pose.PoseLandmark.LEFT_HIP].y * h\n","        offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        neck_inclination = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n","        torso_inclination = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n","\n","        # Determine label based on posture\n","        label = 'good' if offset < 100 and neck_inclination < 40 and torso_inclination < 10 else 'bad'\n","\n","        # Write posture data to CSV file\n","        writer.writerow([l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y,\n","                         l_ear_x, l_ear_y, l_hip_x, l_hip_y,\n","                         neck_inclination, torso_inclination, label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data'\n","    csv_file_path = '/content/posture_dataA.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Left Shoulder X', 'Left Shoulder Y','Right Shoulder X' ,'Right Shoulder Y','','',''])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5t_XRF9YyNih","executionInfo":{"status":"ok","timestamp":1714393035820,"user_tz":-330,"elapsed":17561,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"a585dd31-ee21-4359-eada-98267b8e8364"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_008.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_008.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_023 (1).jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_046.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_041.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_048.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_050.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_049.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_047.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_044.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_040.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_039.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_045.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_042.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_043.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_038.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_051.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_054.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_053.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_056.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_052.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_057.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_055.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","\n","        label = 'good'\n","        # Write posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/good'\n","    csv_file_path = '/content/posture_dataB.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5BGhq5fqz5mN","executionInfo":{"status":"ok","timestamp":1714394194431,"user_tz":-330,"elapsed":2797,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"52ff864d-05c0-454c-ae6a-4c37d1698404"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/good/good_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_023 (1).jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_036.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","\n","        label = 'bad'\n","        # Write posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/bad'\n","    csv_file_path = '/content/badtraining.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qCBn3XT-3TxR","executionInfo":{"status":"ok","timestamp":1714394517966,"user_tz":-330,"elapsed":5250,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"1fecc62f-dc84-4fb0-f8fd-b71933bd8476"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/bad/bad_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_046.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_041.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_048.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_050.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_049.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_047.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_044.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_040.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_039.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_045.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_042.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_043.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_038.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_051.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_054.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_053.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_056.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_052.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_057.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_055.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","\n","        label = 'bad'\n","        # Write posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/bad'\n","    csv_file_path = '/content/badvalidation.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cq8g_7ax4c6I","executionInfo":{"status":"ok","timestamp":1714394649046,"user_tz":-330,"elapsed":1092,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"0888b9e6-85ec-4ee0-ed80-822ccd9e7cf8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_008.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","\n","        label = 'good'\n","        # Write posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/good'\n","    csv_file_path = '/content/goodvalidation.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-ehhF1Z41e6","executionInfo":{"status":"ok","timestamp":1714394746998,"user_tz":-330,"elapsed":1459,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"8e35b1eb-a330-4a9d-c43d-97acca2db3c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_008.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_006.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","\n","        label = 'good'\n","        # Write posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/good'\n","    csv_file_path = '/content/goodtr.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Atu0uiHEJ7pJ","executionInfo":{"status":"ok","timestamp":1714399286005,"user_tz":-330,"elapsed":17043,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"02ee36c0-18c9-477c-e996-a91bed3ed666"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/good/good_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_023 (1).jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_11_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_27_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_09_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_02_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_03_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_12_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_01_42_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_26_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_25_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_10_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_22_Pro (2).jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_45_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","\n","        label = 'bad'\n","        # Write posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/bad'\n","    csv_file_path = '/content/badtr.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-k5pU1IGKcPQ","executionInfo":{"status":"ok","timestamp":1714399443167,"user_tz":-330,"elapsed":15505,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"7f97b8aa-7b02-40fe-8b3e-fdc4db0e6fab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/bad/bad_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_046.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_041.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_048.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_050.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_049.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_047.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_044.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_040.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_039.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_045.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_042.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_043.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_038.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_051.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_054.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_053.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_056.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_052.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_057.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_055.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_31_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_28_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_34_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_17_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_15_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_02_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_01_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_07_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_39_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_01_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_46_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","\n","        label = 'bad'\n","        # Write posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/bad'\n","    csv_file_path = '/content/badval.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1YrBkaiLKVq","executionInfo":{"status":"ok","timestamp":1714399563094,"user_tz":-330,"elapsed":5010,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"86bc1e61-2a4d-4395-838f-fc2f445fba19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_008.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_26_47_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_24_52_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_24_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_24_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_26_48_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_26_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_25_41_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_25_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_26_45_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","\n","        label = 'good'\n","        # Write posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/good'\n","    csv_file_path = '/content/goodval.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ELiyigmnLi4_","executionInfo":{"status":"ok","timestamp":1714399649775,"user_tz":-330,"elapsed":6932,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"72f3466a-9475-4994-f13d-6b3ce0789fe9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_32_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_33_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_47_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_12_21_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["pip install mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFLwUveQ1vK-","executionInfo":{"status":"ok","timestamp":1714410797199,"user_tz":-330,"elapsed":112672,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"8dcccb31-3275-451b-9d5b-d748496f5ecc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mediapipe\n","  Downloading mediapipe-0.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n","Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mediapipe) (2.2.1+cu121)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->mediapipe)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->mediapipe)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->mediapipe)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->mediapipe)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->mediapipe)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->mediapipe)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->mediapipe)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->mediapipe)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->mediapipe)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->mediapipe)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->mediapipe)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->mediapipe)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mediapipe) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mediapipe) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, sounddevice, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mediapipe\n","Successfully installed mediapipe-0.10.11 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sounddevice-0.4.6\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","\n","        label = 'good'\n","        # Write posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/good'\n","    csv_file_path = '/content/gootr.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s1Jo1KZ50iZE","executionInfo":{"status":"ok","timestamp":1714410844186,"user_tz":-330,"elapsed":43333,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"e15ff760-4d3d-4f3d-e980-3dbb088667f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_29_17_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_01_42_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_02_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_03_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_09_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_11_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_12_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_27_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_25_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_26_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_10_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_22_Pro (2).jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_45_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_49_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","\n","        label = 'bad'\n","        # Write posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/bad'\n","    csv_file_path = '/content/batr.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LOtsa9t42uV0","executionInfo":{"status":"ok","timestamp":1714410998605,"user_tz":-330,"elapsed":39746,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"19d54df6-51a7-464b-9fd4-09e02a42195c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/bad/bad_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_038.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_039.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_040.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_041.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_042.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_043.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_044.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_045.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_046.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_047.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_048.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_049.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_050.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_051.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_052.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_053.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_054.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_055.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_056.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_057.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_01_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_01_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_28_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_31_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_02_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_07_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_39_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_15_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_17_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_34_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_28_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_34_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_41_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_48_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_57_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_58_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_52_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_23_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","\n","        label = 'bad'\n","        # Write posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/bad'\n","    csv_file_path = '/content/baval.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oe31azpN3Skr","executionInfo":{"status":"ok","timestamp":1714411121275,"user_tz":-330,"elapsed":10242,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"f1fc5262-f3b1-439c-8289-3ff7c8f3fa68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_28_52_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_27_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_27_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_28_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_27_41_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_29_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_008.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_24_52_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_24_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_24_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_25_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_25_41_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_26_45_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_26_47_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_26_48_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_26_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_27_05_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'good'\n","        # Write posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/good'\n","    csv_file_path = '/content/gooval.csv'\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gB77TTSj3nmG","executionInfo":{"status":"ok","timestamp":1714411297329,"user_tz":-330,"elapsed":2601,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"aba04355-f676-4f0c-e0da-7c272290e5d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_17_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_12_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_47_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_32_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_33_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_44_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["pip install mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMKVyFb2r09f","executionInfo":{"status":"ok","timestamp":1714455898844,"user_tz":-330,"elapsed":88233,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"3e64de65-2feb-4bbe-87f2-f28d07d98094"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mediapipe\n","  Downloading mediapipe-0.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n","Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mediapipe) (2.2.1+cu121)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->mediapipe)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->mediapipe)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->mediapipe)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->mediapipe)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->mediapipe)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->mediapipe)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->mediapipe)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->mediapipe)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->mediapipe)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->mediapipe)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->mediapipe)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->mediapipe)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mediapipe) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mediapipe) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, sounddevice, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mediapipe\n","Successfully installed mediapipe-0.10.11 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sounddevice-0.4.6\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('good')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'good'\n","\n","        # Write original image posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/good'\n","    csv_file_path = '/content/augoodtr.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        rotation_range=20,\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fboYFeQTrOS-","executionInfo":{"status":"ok","timestamp":1714425247176,"user_tz":-330,"elapsed":122797,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"10da95fd-a7db-4180-eb16-67d805e47db7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/good/good_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_01_42_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_02_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_03_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_09_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_11_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_12_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_27_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_25_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_26_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_10_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_22_Pro (2).jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_45_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_29_17_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('bad')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'bad'\n","\n","        # Write original image posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/bad'\n","    csv_file_path = '/content/aubadtr.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        rotation_range=20,\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5iEWZw7toy7","executionInfo":{"status":"ok","timestamp":1714425573288,"user_tz":-330,"elapsed":181679,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"217f5230-256b-4b71-d3fe-0ece29fc0a02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/bad/bad_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_038.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_039.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_040.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_041.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_042.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_043.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_044.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_045.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_046.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_047.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_048.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_049.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_050.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_051.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_052.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_053.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_054.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_055.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_056.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_057.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_01_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_01_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_28_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_31_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_02_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_07_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_39_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_15_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_17_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_34_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_28_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_34_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_41_Pro.jpg\n","No landmarks detected in augmented image /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_41_Pro.jpg\n","No landmarks detected in augmented image /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_41_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_48_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_57_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_58_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_52_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_23_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('good')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'good'\n","\n","        # Write original image posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/good'\n","    csv_file_path = '/content/augoodval.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        rotation_range=20,\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPrEA7U1u0Ye","executionInfo":{"status":"ok","timestamp":1714425715470,"user_tz":-330,"elapsed":45309,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"b8f660dd-c8f9-42ae-e859-8746332d960a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_12_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_47_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_32_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_33_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_17_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('bad')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'bad'\n","\n","        # Write original image posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/bad'\n","    csv_file_path = '/content/au1badtr.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        rotation_range=20,\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVegoS05vROb","executionInfo":{"status":"ok","timestamp":1714427163418,"user_tz":-330,"elapsed":149532,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"69d8c1d4-355d-4bc2-b78b-caafd98a155e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/bad/bad_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_038.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_039.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_040.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_041.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_042.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_043.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_044.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_045.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_046.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_047.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_048.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_049.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_050.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_051.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_052.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_053.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_054.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_055.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_056.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_057.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_01_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_01_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_28_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_31_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_02_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_07_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_39_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_15_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_17_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_34_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_28_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_34_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_41_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_48_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_57_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_58_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_52_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_23_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('good')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'good'\n","\n","        # Write original image posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/good'\n","    csv_file_path = '/content/au1goodtr.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        rotation_range=20,\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U5gfg4FU0tXJ","executionInfo":{"status":"ok","timestamp":1714427349037,"user_tz":-330,"elapsed":118704,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"6ad57865-606b-47d1-b18f-70586bf0babf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/good/good_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_01_42_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_02_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_03_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_09_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_11_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_12_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_27_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_25_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_26_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_10_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_22_Pro (2).jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_45_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_29_17_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('good')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'good'\n","\n","        # Write original image posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/good'\n","    csv_file_path = '/content/au1goodval.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        rotation_range=20,\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vBseU7b1dzM","executionInfo":{"status":"ok","timestamp":1714427455061,"user_tz":-330,"elapsed":37824,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"833aee5c-6508-41e0-a65e-d31e03d467a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_12_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_47_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_32_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_33_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_17_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('bad')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'bad'\n","\n","        # Write original image posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/good'\n","    csv_file_path = '/content/newbad.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        rotation_range=40,\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2eMTGMNHhz3V","executionInfo":{"status":"ok","timestamp":1714456236671,"user_tz":-330,"elapsed":162291,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"2a776908-a631-4734-f507-e38e450c6d36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/good/good_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_01_42_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_02_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_03_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_09_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_11_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_12_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_27_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_25_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_26_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_10_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_22_Pro (2).jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_45_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_29_17_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('bad')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'bad'\n","\n","        # Write original image posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/bad'\n","    csv_file_path = '/content/newbadtrb.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        rotation_range=40,\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCqLmYLUkFXY","executionInfo":{"status":"ok","timestamp":1714456625954,"user_tz":-330,"elapsed":200386,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"e4dea920-c0ab-41c8-cd2c-449f2fa7eb19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/bad/bad_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_019.jpg\n","No landmarks detected in augmented image /content/drive/MyDrive/data/training/bad/bad_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_038.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_039.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_040.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_041.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_042.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_043.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_044.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_045.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_046.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_047.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_048.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_049.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_050.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_051.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_052.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_053.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_054.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_055.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_056.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_057.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_01_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_01_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_28_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_31_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_02_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_07_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_39_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_15_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_17_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_34_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_28_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_34_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_41_Pro.jpg\n","No landmarks detected in augmented image /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_41_Pro.jpg\n","No landmarks detected in augmented image /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_41_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_48_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_57_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_58_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_52_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_23_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('bad')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'bad'\n","\n","        # Write original image posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/bad'\n","    csv_file_path = '/content/newbadvalb.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        rotation_range=40,\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAMqXCVOlKfk","executionInfo":{"status":"ok","timestamp":1714456744230,"user_tz":-330,"elapsed":51000,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"21ff2970-61b6-476d-8a4c-8713a511ba41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/bad_posture_val_008.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_24_52_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_24_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_24_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_25_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_25_41_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_26_45_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_26_47_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_26_48_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_19_26_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_27_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_27_41_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_27_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_27_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_28_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_28_52_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/bad/WIN_20240429_22_29_13_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('bad')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'bad'\n","\n","        # Write original image posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/good'\n","    csv_file_path = '/content/newbadvalg.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        rotation_range=40,\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NW8rKDqVloS0","executionInfo":{"status":"ok","timestamp":1714456884852,"user_tz":-330,"elapsed":46110,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"f169d1c4-20b9-4629-9c1b-77e337008849"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_12_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_47_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_32_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_33_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_17_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('good')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        #offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        #nose_angle = findAngle(l_shldr_x, l_shldr_y, nose_x, nose_y)\n","        #torso_inclination = findAngle(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'good'\n","\n","        # Write original image posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/good'\n","    csv_file_path = '/content/newgoodtr.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WjeDtF-2mZ_v","executionInfo":{"status":"ok","timestamp":1714457173066,"user_tz":-330,"elapsed":105360,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"2711fb8b-55fa-4489-c500-e9e8a24c640e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/good/good_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_01_42_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_02_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_03_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_09_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_11_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_12_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_27_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_25_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_26_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_10_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_22_Pro (2).jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_45_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_29_17_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('bad')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        label = 'bad'\n","\n","        # Write original image posture data to CSV file\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/good'\n","    csv_file_path = '/content/finbadtrg.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        rotation_range=40,\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w8M75G98nUaI","executionInfo":{"status":"ok","timestamp":1714457284702,"user_tz":-330,"elapsed":34630,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"3e4c5fbb-3454-4398-c378-937933809c29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_12_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_47_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_32_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_33_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_17_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('bad')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","\n","        label = 'bad'\n","        left_eye_x = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].x * w - r_shldr_x\n","        left_eye_y = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].y * h - r_shldr_y\n","        left_eye_z = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].z * h\n","        right_eye_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].x * w - r_shldr_x\n","        right_eye_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].y * h - r_shldr_y\n","        right_eye_z = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].z * h\n","        left_lip_x = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].x * w - r_shldr_x\n","        left_lip_y = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].y * h - r_shldr_y\n","        left_lip_z = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].z * h\n","        right_lip_x = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].x * w - r_shldr_x\n","        right_lip_y = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].y * h - r_shldr_y\n","        right_lip_z = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].z * h\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,left_eye_x, left_eye_y,left_eye_z, right_eye_x, right_eye_y,right_eye_z ,left_lip_x, left_lip_y, left_lip_z ,right_lip_x, right_lip_y,right_lip_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","\n","                left_eye_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].x * w- r_shldr_x_aug\n","                left_eye_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].y * h- r_shldr_y_aug\n","                left_eye_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].z * h\n","                right_eye_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].x * w- r_shldr_x_aug\n","                right_eye_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].y * h- r_shldr_y_aug\n","                right_eye_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].z * h\n","                left_lip_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].x * w- r_shldr_x_aug\n","                left_lip_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].y * h- r_shldr_y_aug\n","                left_lip_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].z * h\n","                right_lip_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].x * w- r_shldr_x_aug\n","                right_lip_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].y * h- r_shldr_y_aug\n","                right_lip_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].z * h\n","\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,left_eye_x,left_eye_y,left_eye_z,right_eye_x,right_eye_y,right_eye_z,left_lip_x,left_lip_y,left_lip_z,right_lip_x,right_lip_y,right_lip_z,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/good'\n","    csv_file_path = '/content/finbadtrg.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Left Eye X','Left Eye Y','Left Eye Z','Right Eye X','Right Eye Y','Right Eye Z','Left Lip X','Left Lip Y','Left Lip Z','Right Lip X','Right Lip Y','Right Lip Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DrGPYCyc74hp","executionInfo":{"status":"ok","timestamp":1714464184416,"user_tz":-330,"elapsed":102820,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"56686019-871a-44ae-b298-c94d468da157"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/good/good_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/good/good_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_01_42_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_02_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_03_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_03_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_04_09_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_11_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_12_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_05_27_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_06_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_25_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_07_26_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_09_10_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_20_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_12_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_22_Pro (2).jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_23_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_45_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_19_13_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/good/WIN_20240429_22_29_17_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('bad')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","\n","        label = 'bad'\n","        left_eye_x = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].x * w - r_shldr_x\n","        left_eye_y = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].y * h - r_shldr_y\n","        left_eye_z = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].z * h\n","        right_eye_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].x * w - r_shldr_x\n","        right_eye_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].y * h - r_shldr_y\n","        right_eye_z = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].z * h\n","        left_lip_x = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].x * w - r_shldr_x\n","        left_lip_y = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].y * h - r_shldr_y\n","        left_lip_z = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].z * h\n","        right_lip_x = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].x * w - r_shldr_x\n","        right_lip_y = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].y * h - r_shldr_y\n","        right_lip_z = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].z * h\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,left_eye_x, left_eye_y,left_eye_z, right_eye_x, right_eye_y,right_eye_z ,left_lip_x, left_lip_y, left_lip_z ,right_lip_x, right_lip_y,right_lip_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","\n","                left_eye_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].x * w- r_shldr_x_aug\n","                left_eye_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].y * h- r_shldr_y_aug\n","                left_eye_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].z * h\n","                right_eye_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].x * w- r_shldr_x_aug\n","                right_eye_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].y * h- r_shldr_y_aug\n","                right_eye_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].z * h\n","                left_lip_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].x * w- r_shldr_x_aug\n","                left_lip_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].y * h- r_shldr_y_aug\n","                left_lip_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].z * h\n","                right_lip_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].x * w- r_shldr_x_aug\n","                right_lip_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].y * h- r_shldr_y_aug\n","                right_lip_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].z * h\n","\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,left_eye_x,left_eye_y,left_eye_z,right_eye_x,right_eye_y,right_eye_z,left_lip_x,left_lip_y,left_lip_z,right_lip_x,right_lip_y,right_lip_z,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/training/bad'\n","    csv_file_path = '/content/finbadtrb.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Left Eye X','Left Eye Y','Left Eye Z','Right Eye X','Right Eye Y','Right Eye Z','Left Lip X','Left Lip Y','Left Lip Z','Right Lip X','Right Lip Y','Right Lip Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Twx80MsBCJ4v","executionInfo":{"status":"ok","timestamp":1714464440516,"user_tz":-330,"elapsed":132984,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"06ddb3a1-db65-4542-e3ef-2a3defa954dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/training/bad/bad_posture_001.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_002.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_003.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_004.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_005.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_006.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_007.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_008.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_009.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_010.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_011.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_012.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_013.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_014.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_015.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_016.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_017.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_018.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_019.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_020.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_021.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_022.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_023.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_024.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_025.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_026.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_027.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_028.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_029.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_030.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_031.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_032.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_033.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_034.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_035.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_036.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_037.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_038.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_039.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_040.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_041.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_042.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_043.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_044.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_045.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_046.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_047.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_048.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_049.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_050.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_051.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_052.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_053.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_054.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_055.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_056.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/bad_posture_057.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_01_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_01_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_24_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_28_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_31_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_02_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_02_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_07_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_39_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_03_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_15_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_05_36_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_16_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_17_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_19_07_34_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_28_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_34_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_41_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_48_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_51_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_57_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_58_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_27_59_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_28_52_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_13_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_22_Pro.jpg\n","Processing: /content/drive/MyDrive/data/training/bad/WIN_20240429_22_29_23_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('bad')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","\n","        label = 'bad'\n","        left_eye_x = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].x * w - r_shldr_x\n","        left_eye_y = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].y * h - r_shldr_y\n","        left_eye_z = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].z * h\n","        right_eye_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].x * w - r_shldr_x\n","        right_eye_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].y * h - r_shldr_y\n","        right_eye_z = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].z * h\n","        left_lip_x = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].x * w - r_shldr_x\n","        left_lip_y = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].y * h - r_shldr_y\n","        left_lip_z = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].z * h\n","        right_lip_x = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].x * w - r_shldr_x\n","        right_lip_y = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].y * h - r_shldr_y\n","        right_lip_z = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].z * h\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,left_eye_x, left_eye_y,left_eye_z, right_eye_x, right_eye_y,right_eye_z ,left_lip_x, left_lip_y, left_lip_z ,right_lip_x, right_lip_y,right_lip_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","\n","                left_eye_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].x * w- r_shldr_x_aug\n","                left_eye_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].y * h- r_shldr_y_aug\n","                left_eye_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].z * h\n","                right_eye_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].x * w- r_shldr_x_aug\n","                right_eye_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].y * h- r_shldr_y_aug\n","                right_eye_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].z * h\n","                left_lip_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].x * w- r_shldr_x_aug\n","                left_lip_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].y * h- r_shldr_y_aug\n","                left_lip_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].z * h\n","                right_lip_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].x * w- r_shldr_x_aug\n","                right_lip_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].y * h- r_shldr_y_aug\n","                right_lip_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].z * h\n","\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,left_eye_x,left_eye_y,left_eye_z,right_eye_x,right_eye_y,right_eye_z,left_lip_x,left_lip_y,left_lip_z,right_lip_x,right_lip_y,right_lip_z,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/good'\n","    csv_file_path = '/content/finbadvalg.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Left Eye X','Left Eye Y','Left Eye Z','Right Eye X','Right Eye Y','Right Eye Z','Left Lip X','Left Lip Y','Left Lip Z','Right Lip X','Right Lip Y','Right Lip Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S53G1rqOC_PI","executionInfo":{"status":"ok","timestamp":1714464641623,"user_tz":-330,"elapsed":33338,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"78b3712b-e8b3-4b37-bb13-a33fc18478b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_12_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_47_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_32_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_33_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_17_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('bad')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","\n","        label = 'good'\n","        left_eye_x = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].x * w - r_shldr_x\n","        left_eye_y = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].y * h - r_shldr_y\n","        left_eye_z = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].z * h\n","        right_eye_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].x * w - r_shldr_x\n","        right_eye_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].y * h - r_shldr_y\n","        right_eye_z = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].z * h\n","        left_lip_x = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].x * w - r_shldr_x\n","        left_lip_y = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].y * h - r_shldr_y\n","        left_lip_z = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].z * h\n","        right_lip_x = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].x * w - r_shldr_x\n","        right_lip_y = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].y * h - r_shldr_y\n","        right_lip_z = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].z * h\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,left_eye_x, left_eye_y,left_eye_z, right_eye_x, right_eye_y,right_eye_z ,left_lip_x, left_lip_y, left_lip_z ,right_lip_x, right_lip_y,right_lip_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","\n","                left_eye_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].x * w- r_shldr_x_aug\n","                left_eye_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].y * h- r_shldr_y_aug\n","                left_eye_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].z * h\n","                right_eye_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].x * w- r_shldr_x_aug\n","                right_eye_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].y * h- r_shldr_y_aug\n","                right_eye_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].z * h\n","                left_lip_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].x * w- r_shldr_x_aug\n","                left_lip_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].y * h- r_shldr_y_aug\n","                left_lip_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].z * h\n","                right_lip_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].x * w- r_shldr_x_aug\n","                right_lip_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].y * h- r_shldr_y_aug\n","                right_lip_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].z * h\n","\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,left_eye_x,left_eye_y,left_eye_z,right_eye_x,right_eye_y,right_eye_z,left_lip_x,left_lip_y,left_lip_z,right_lip_x,right_lip_y,right_lip_z,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/good'\n","    csv_file_path = '/content/finbadvalg.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Left Eye X','Left Eye Y','Left Eye Z','Right Eye X','Right Eye Y','Right Eye Z','Left Lip X','Left Lip Y','Left Lip Z','Right Lip X','Right Lip Y','Right Lip Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"1y05LGWBDyxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import mediapipe as mp\n","import csv\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","mp_pose = mp.solutions.pose\n","\n","\"\"\"def findDistance(x1, y1, x2, y2):\n","    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n","    return dist\n","\n","def findAngle(x1, y1, x2, y2):\n","    if (x2 - x1) == 0 or y1 == 0:\n","        return 0\n","    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n","    degree = int(180 / math.pi) * theta\n","    return degree\"\"\"\n","\n","def process_image(image_path, writer, pose, datagen):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Failed to read image from {image_path}\")\n","        return\n","\n","    h, w = image.shape[:2]\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","    augmented_data = datagen.flow(np.expand_dims(image_rgb, axis=0), batch_size=1)\n","    for i in range(5):  # Augment each image 5 times\n","        augmented_image = augmented_data.next()[0].astype(np.uint8)\n","        augmented_images.append(augmented_image)\n","        augmented_labels.append('good')\n","\n","    keypoints = pose.process(image_rgb)\n","    lm = keypoints.pose_landmarks\n","\n","    if lm is not None:\n","        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","        l_shldr_x -= r_shldr_x\n","        l_shldr_y -= r_shldr_y\n","        nose_x -= r_shldr_x\n","        nose_y -= r_shldr_y\n","\n","        label = 'good'\n","        left_eye_x = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].x * w - r_shldr_x\n","        left_eye_y = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].y * h - r_shldr_y\n","        left_eye_z = lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].z * h\n","        right_eye_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].x * w - r_shldr_x\n","        right_eye_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].y * h - r_shldr_y\n","        right_eye_z = lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].z * h\n","        left_lip_x = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].x * w - r_shldr_x\n","        left_lip_y = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].y * h - r_shldr_y\n","        left_lip_z = lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].z * h\n","        right_lip_x = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].x * w - r_shldr_x\n","        right_lip_y = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].y * h - r_shldr_y\n","        right_lip_z = lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].z * h\n","        r_shldr_x = 0\n","        r_shldr_y = 0\n","\n","        writer.writerow([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z,left_eye_x, left_eye_y,left_eye_z, right_eye_x, right_eye_y,right_eye_z ,left_lip_x, left_lip_y, left_lip_z ,right_lip_x, right_lip_y,right_lip_z,label])\n","\n","        # Write augmented image posture data to CSV file\n","        for augmented_image in augmented_images:\n","            augmented_keypoints = pose.process(augmented_image)\n","            augmented_lm = augmented_keypoints.pose_landmarks\n","\n","            if augmented_lm is not None:\n","                nose_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n","                nose_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n","                nose_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n","\n","                l_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n","                l_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n","                l_shldr_z_aug = augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n","                r_shldr_x_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n","                r_shldr_y_aug = augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n","                r_shldr_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n","                l_shldr_x_aug -= r_shldr_x_aug\n","                l_shldr_y_aug -= r_shldr_y_aug\n","                nose_x_aug -=r_shldr_x_aug\n","                nose_y_aug -= r_shldr_y_aug\n","\n","                left_eye_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].x * w- r_shldr_x_aug\n","                left_eye_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].y * h- r_shldr_y_aug\n","                left_eye_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.LEFT_EYE].z * h\n","                right_eye_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].x * w- r_shldr_x_aug\n","                right_eye_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].y * h- r_shldr_y_aug\n","                right_eye_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.RIGHT_EYE].z * h\n","                left_lip_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].x * w- r_shldr_x_aug\n","                left_lip_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].y * h- r_shldr_y_aug\n","                left_lip_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].z * h\n","                right_lip_x_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].x * w- r_shldr_x_aug\n","                right_lip_y_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].y * h- r_shldr_y_aug\n","                right_lip_z_aug=augmented_lm.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].z * h\n","\n","                r_shldr_x_aug = 0\n","                r_shldr_y_aug = 0\n","\n","                writer.writerow([nose_x_aug, nose_y_aug, nose_z_aug, l_shldr_x_aug,l_shldr_y_aug,l_shldr_z_aug,r_shldr_x_aug,r_shldr_y_aug,r_shldr_z_aug,left_eye_x,left_eye_y,left_eye_z,right_eye_x,right_eye_y,right_eye_z,left_lip_x,left_lip_y,left_lip_z,right_lip_x,right_lip_y,right_lip_z,label])\n","            else:\n","                print(f\"No landmarks detected in augmented image {image_path}\")\n","\n","    else:\n","        print(f\"No landmarks detected in image {image_path}\")\n","\n","def process_images_recursively(folder_path, writer, pose, datagen):\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            if filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\"):\n","                image_path = os.path.join(root, filename)\n","                print(\"Processing:\", image_path)\n","                process_image(image_path, writer, pose, datagen)\n","\n","def main():\n","    folder_path = '/content/drive/MyDrive/data/validation/good'\n","    csv_file_path = '/content/fingoodvalg.csv'\n","\n","    # Define data generator with augmentation parameters\n","    datagen = ImageDataGenerator(\n","        zoom_range=0.2,\n","        fill_mode='nearest')\n","\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Nose X', 'Nose Y', 'Nose Z','Left Shoulder X', 'Left Shoulder Y','Left Shoulder Z','Right Shoulder X' ,'Right Shoulder Y', 'Right Shoulder Z','Left Eye X','Left Eye Y','Left Eye Z','Right Eye X','Right Eye Y','Right Eye Z','Left Lip X','Left Lip Y','Left Lip Z','Right Lip X','Right Lip Y','Right Lip Z','Label'])\n","\n","        pose = mp_pose.Pose()\n","        process_images_recursively(folder_path, writer, pose, datagen)\n","        pose.close()\n","\n","    print('Finished processing images and saving data to CSV.')\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GvbHmdaxEMNp","executionInfo":{"status":"ok","timestamp":1714467454427,"user_tz":-330,"elapsed":33870,"user":{"displayName":"Priya MG","userId":"10912663313795183542"}},"outputId":"c7aeb510-cdf6-4bd4-ca88-a0458531813f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_001.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_002.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_003.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_004.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_005.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_006.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/good_posture_val_007.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_12_21_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_46_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_47_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_24_56_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_32_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_33_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_25_49_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_40_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_19_26_44_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_53_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_27_54_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_18_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_28_19_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_05_Pro.jpg\n","Processing: /content/drive/MyDrive/data/validation/good/WIN_20240429_22_29_17_Pro.jpg\n","Finished processing images and saving data to CSV.\n"]}]}]}